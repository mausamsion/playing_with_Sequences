{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "english_to_hindi_machine_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "12edSaCSPGtfrPyRkjVGM04dh5RoSDmu8",
      "authorship_tag": "ABX9TyN7X1oziUm1wnQRBXdgH/XZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mausamsion/playing_with_Sequences/blob/master/english_to_hindi_machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wg3qWwGjSb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install indic-nlp-library\n",
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQy396Hr4qGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b2b5e462-f1a4-4795-8a94-33bdb1d3fed9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep  8 09:22:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeDVYaRTHT13",
        "colab_type": "text"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_liAXNaHIyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "8201f9ee-7469-4a6c-965b-8dd3f62be0c5"
      },
      "source": [
        "!mkdir mtdata\n",
        "!tar -C mtdata -xvzf drive/My\\ Drive/datasets/hindi_english_mt/dev_test.tgz\n",
        "# !tar -C mtdata -xvzf drive/My\\ Drive/datasets/hindi_english_mt/monolingual.hi.tgz\n",
        "!tar -C mtdata -xvzf drive/My\\ Drive/datasets/hindi_english_mt/parallel.tgz\n",
        "# !tar -C mtdata -xvzf drive/My\\ Drive/datasets/hindi_english_mt/prunedCorpus.tar.gz\n",
        "# !tar -C mtdata -xvzf drive/My\\ Drive/datasets/hindi_english_mt/xlit-iitb-par.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev_test/\n",
            "dev_test/dev.hi\n",
            "dev_test/test.hi\n",
            "dev_test/dev.en\n",
            "dev_test/test.en\n",
            "parallel/\n",
            "parallel/IITB.en-hi.hi\n",
            "parallel/IITB.en-hi.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAo7tRNsnNDU",
        "colab_type": "text"
      },
      "source": [
        "## Preparing CSVs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6i9f2PcHI-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Reading train data\n",
        "# with open('mtdata/parallel/IITB.en-hi.hi', 'rb') as f:\n",
        "#     train_hi = f.readlines()\n",
        "# train_hi = [i[:-1].decode() for i in train_hi]\n",
        "\n",
        "# with open('mtdata/parallel/IITB.en-hi.en', 'rb') as f:\n",
        "#     train_en = f.readlines()\n",
        "# train_en = [i[:-1].decode() for i in train_en]\n",
        "\n",
        "# # Reading dev data\n",
        "# with open('mtdata/dev_test/dev.hi', 'rb') as f:\n",
        "#     val_hi = f.readlines()\n",
        "# val_hi = [i[:-1].decode() for i in val_hi]\n",
        "\n",
        "# with open('mtdata/dev_test/dev.en', 'rb') as f:\n",
        "#     val_en = f.readlines()\n",
        "# val_en = [i[:-1].decode() for i in val_en]\n",
        "\n",
        "# # Reading test data\n",
        "# with open('mtdata/dev_test/test.hi', 'rb') as f:\n",
        "#     test_hi = f.readlines()\n",
        "# test_hi = [i[:-1].decode() for i in test_hi]\n",
        "\n",
        "# with open('mtdata/dev_test/test.en', 'rb') as f:\n",
        "#     test_en = f.readlines()\n",
        "# test_en = [i[:-1].decode() for i in test_en]\n",
        "\n",
        "# # ------------------------------------------\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# train_pairs = pd.DataFrame()\n",
        "# train_pairs['ENGLISH'] = train_en\n",
        "# train_pairs['HINDI'] = train_hi\n",
        "# train_pairs.to_csv('drive/My Drive/datasets/hindi_english_mt/train_pairs.csv', index=None)\n",
        "# train_pairs_small = train_pairs.sample(frac=0.4, replace=False)\n",
        "# train_pairs_small.to_csv('drive/My Drive/datasets/hindi_english_mt/train_pairs_small.csv', index=None)\n",
        "\n",
        "# val_pairs = pd.DataFrame()\n",
        "# val_pairs['ENGLISH'] = val_en\n",
        "# val_pairs['HINDI'] = val_hi\n",
        "# val_pairs.to_csv('drive/My Drive/datasets/hindi_english_mt/val_pairs.csv', index=None)\n",
        "\n",
        "# test_pairs = pd.DataFrame()\n",
        "# test_pairs['ENGLISH'] = test_en\n",
        "# test_pairs['HINDI'] = test_hi\n",
        "# test_pairs.to_csv('drive/My Drive/datasets/hindi_english_mt/test_pairs.csv', index=None)\n",
        "\n",
        "# del train_en, train_hi, val_en, val_hi, test_en, test_hi, train_pairs, dev_pairs, test_pairs\n",
        "\n",
        "# !wc -l drive/My\\ Drive/datasets/hindi_english_mt/*csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHisSpcIL05r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fa8902fb-eac3-4f65-ec78-392d27cbc904"
      },
      "source": [
        "!wc -l drive/My\\ Drive/datasets/hindi_english_mt/*csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     2508 drive/My Drive/datasets/hindi_english_mt/test_pairs.csv\n",
            "  1561841 drive/My Drive/datasets/hindi_english_mt/train_pairs.csv\n",
            "   624737 drive/My Drive/datasets/hindi_english_mt/train_pairs_small.csv\n",
            "      521 drive/My Drive/datasets/hindi_english_mt/val_pairs.csv\n",
            "  2189607 total\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tpOszrCjmKK",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz6cEW6xj3UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "from torchtext.data.metrics import bleu_score as BLEU_SCORE\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from indicnlp.tokenize import indic_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQSOtqDnjkAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUpAMPc3nZXl",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizer, Dataset, Iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mfq7t1p1Tpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_en = spacy.load('en') \n",
        "indic_hi = indic_tokenize.trivial_tokenize_indic\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text) if not tok.is_quote]\n",
        "\n",
        "def tokenize_hi(text):\n",
        "    text = indic_hi(text)\n",
        "    return [tok for tok in text if not tok in ['\"',\"'\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoO9oIQtkaEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC = Field(tokenize=tokenize_en,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>',\n",
        "            lower=True)\n",
        "TRG = Field(tokenize=tokenize_hi,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQFanVs7jBSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bc6b725-312a-4bd2-8ca1-5b49e432dabb"
      },
      "source": [
        "train_dataset, val_dataset, test_dataset = TabularDataset.splits(\n",
        "    path='drive/My Drive/datasets/hindi_english_mt', \n",
        "    train='train_pairs_small.csv', validation='val_pairs.csv', test='test_pairs.csv', format='csv',\n",
        "    fields=[('English', SRC), ('Hindi', TRG)], \n",
        "    skip_header=True\n",
        ")\n",
        "print('train:', len(train_dataset), \n",
        "      ', val:', len(val_dataset), \n",
        "      ', test:', len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 624736 , val: 520 , test: 2507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9RZe26UnRsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_dataset[0].English)\n",
        "print(test_dataset[0].Hindi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1OvVBLnRpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC.build_vocab(train_dataset, val_dataset, test_dataset, max_size=70000)\n",
        "TRG.build_vocab(train_dataset, val_dataset, test_dataset, max_size=70000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6ZySwlkoUjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f83fc05-83e6-4b24-9ddf-8381ac307d01"
      },
      "source": [
        "def get_default_device():\n",
        "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    def __iter__(self):\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "    \n",
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukKqDtMKohZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_iter = BucketIterator(train_dataset, batch_size=BATCH_SIZE, device=device, \n",
        "                            sort_key=lambda x: len(x.English), sort_within_batch=False, \n",
        "                            repeat=False)\n",
        "\n",
        "val_iter = Iterator(val_dataset, batch_size=8, train=False, device=device, \n",
        "                    sort=False, sort_within_batch=False, repeat=False)\n",
        "\n",
        "test_iter = Iterator(test_dataset, batch_size=8, train=False, device=device, \n",
        "                     sort=False, sort_within_batch=False, repeat=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJgrtmPdnI7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What's inside batch\n",
        "for i in train_iter:\n",
        "    print(i, '\\n')\n",
        "    for seqen, seqhi in zip(i.English.T, i.Hindi.T):\n",
        "        for id in seqen:\n",
        "            print(SRC.vocab.itos[id], end=' ')\n",
        "        print('\\n')\n",
        "        for id in seqhi:\n",
        "            print(TRG.vocab.itos[id], end=' ')\n",
        "        print('\\n\\n')\n",
        "        break\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvlBq2J3hgTD",
        "colab_type": "text"
      },
      "source": [
        "## Encoder-Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VtISfB92uv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vanilla encoder-decoder architecture from the following paper:\n",
        "# \"Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation\"\n",
        "# by Cho et al. (https://arxiv.org/pdf/1406.1078.pdf)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim)\n",
        "        self.linear = nn.Linear(enc_hid_dim, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        embed = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.rnn(embed)\n",
        "        hidden = torch.tanh(self.linear(hidden))\n",
        "        return output, hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim + dec_hid_dim*2, dec_hid_dim)\n",
        "        self.linear = nn.Linear(dec_hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, context):\n",
        "        embed = self.dropout(self.embedding(input))\n",
        "        embed = embed.unsqueeze(0)\n",
        "        input = torch.cat((embed, hidden, context), dim=2)\n",
        "        output, hidden = self.rnn(input)\n",
        "        output = self.linear(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "    \n",
        "    def forward(self, source_sent, target_sent='', custom_test='False'):\n",
        "        # if custom_test:\n",
        "        #     target_vocab_size = self.decoder.output_dim\n",
        "        #     encoder_outputs, encoder_hidden = self.encoder(source_sent)\n",
        "        #     decoder_input = TRG.vocab.stoi('<sos>')\n",
        "        #     pred_len = 0\n",
        "        #     while pred_len <= 30:\n",
        "        #         decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_hidden)\n",
        "        #         decoder_output\n",
        "        #         pred_len += 1\n",
        "        #         if pred == '<eos>':\n",
        "        #             break\n",
        "        target_len = target_sent.shape[0]\n",
        "        target_vocab_size = self.decoder.output_dim\n",
        "        decoder_outputs = torch.zeros(target_len, target_sent.shape[1], target_vocab_size).to(device)\n",
        "        encoder_outputs, encoder_hidden = self.encoder(source_sent)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_input = target_sent[0, :]\n",
        "        for t in range(1, target_len):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_hidden)\n",
        "            decoder_outputs[t] = decoder_output\n",
        "            decoder_input = target_sent[t]\n",
        "        return decoder_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN5h3Mqggjnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smoothing = SmoothingFunction().method3\n",
        "def get_bleu(output, target, print_seqs=False):\n",
        "    def trim_pad(target):\n",
        "        new_target = []\n",
        "        for seq in target:\n",
        "            new_seq = []\n",
        "            for i in seq[1:]:\n",
        "                if TRG.vocab.itos[i] == '<eos>':\n",
        "                    break\n",
        "                new_seq.append(i.item())\n",
        "            new_target.append(new_seq)\n",
        "        return new_target\n",
        "\n",
        "    def fix_output(output):\n",
        "        new_output = []\n",
        "        output = output.permute(1,0,2)\n",
        "        softmax = torch.nn.Softmax(dim=1)\n",
        "        for out in output:\n",
        "            tmp = list(torch.argmax(softmax(out), dim=1))\n",
        "            new_output.append(tmp)\n",
        "        new_output = trim_pad(new_output)\n",
        "        return new_output\n",
        "\n",
        "    target = trim_pad(target.T)\n",
        "    output = fix_output(output)\n",
        "    \n",
        "    tmp_bleu = 0\n",
        "    counter = 0\n",
        "    assert len(target) == len(output)\n",
        "    for tar, out in zip(target, output):\n",
        "        tmp_bleu += corpus_bleu([[tar]], [out], smoothing_function=smoothing)\n",
        "    tmp_bleu = tmp_bleu / len(target)\n",
        "    \n",
        "    if print_seqs:\n",
        "        for tar, out in zip(target, output):\n",
        "            print('----------------------')\n",
        "            print(tar)\n",
        "            print(out)\n",
        "        print('----------------------')\n",
        "\n",
        "    return tmp_bleu\n",
        "\n",
        "\n",
        "def get_acc(references, hypotheses, acc_type='word'):\n",
        "    assert acc_type == 'word_acc' or acc_type == 'sent_acc'\n",
        "    cum_acc = 0.\n",
        "\n",
        "    for ref, hyp in zip(references, hypotheses):\n",
        "        ref = ref[1:-1]\n",
        "        hyp = hyp[1:-1]\n",
        "        if acc_type == 'word_acc':\n",
        "            acc = len([1 for ref_w, hyp_w in zip(ref, hyp) if ref_w == hyp_w]) / float(len(hyp) + 1e-6)\n",
        "        else:\n",
        "            acc = 1. if all(ref_w == hyp_w for ref_w, hyp_w in zip(ref, hyp)) else 0.\n",
        "        cum_acc += acc\n",
        "\n",
        "    acc = cum_acc / len(hypotheses)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58mEyO0f2u84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.6\n",
        "DEC_DROPOUT = 0.6\n",
        "ENC = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "DEC = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqfXv74-2u5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA9s_kd32u36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = 'drive/My Drive/datasets/hindi_english_mt/best_model_1.pt'\n",
        "ckp = None\n",
        "if not checkpoint == '':\n",
        "    ckp = torch.load(checkpoint)\n",
        "\n",
        "model = Seq2Seq(ENC, DEC).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "if not ckp == None:\n",
        "    model.load_state_dict(ckp['state_dict'])\n",
        "    # optimizer.load_state_dict(ckp['optimizer'])\n",
        "else:\n",
        "    model.apply(init_weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp6sHjks2utA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30c94718-53ae-4dd0-89dc-3f7bd7e3aed9"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 75,955,060 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqKyKnP1jCgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frxUch5VjCnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    bscore = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.English\n",
        "        trg = batch.Hindi\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        bscore += get_bleu(output, trg)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator), bscore / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1Zt4KBKjC1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    bscore = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.English\n",
        "            trg = batch.Hindi\n",
        "            output = model(src, trg)\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "            bscore += get_bleu(output, trg)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator), bscore / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L0DAeQ_jC7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDDE0hKCkwCC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "4e7e0dd2-de17-4425-bde2-5f2d209753af"
      },
      "source": [
        "STEPS = 200000\n",
        "N_EPOCHS = 1000\n",
        "CLIP = 1\n",
        "log_steps = 2000\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "global_steps = 0\n",
        "step_time = 0\n",
        "train_loss = 0\n",
        "bscore = 0\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    model.train()\n",
        "    for i, batch in enumerate(train_iter):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        src = batch.English\n",
        "        trg = batch.Hindi\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        bscore += get_bleu(output, trg)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        end_time = time.time()\n",
        "        step_time += end_time - start_time\n",
        "        \n",
        "        global_steps += 1\n",
        "        if global_steps % log_steps == 0:\n",
        "            avg_train_loss = train_loss / log_steps\n",
        "            avg_train_bleu = bscore / log_steps\n",
        "            avg_step_time = step_time / log_steps\n",
        "            val_loss, val_bleu = evaluate(model, val_iter, criterion)\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                cp = {'global_steps': global_steps, \n",
        "                      'state_dict': model.state_dict(),\n",
        "                      'optimizer': optimizer.state_dict()}\n",
        "                torch.save(cp, 'drive/My Drive/datasets/hindi_english_mt/best_model_2.pt')\n",
        "            print(f'Global step: {global_steps} | '\n",
        "                  f'Avg_step_time: {avg_step_time:.2f}s | '\n",
        "                  f'Train Loss: {avg_train_loss:.4f} | '\n",
        "                  f'Val. Loss: {val_loss:.4f} | '\n",
        "                  f'Train Bleu: {avg_train_bleu:.4f} | '\n",
        "                  f'Val. Bleu: {val_bleu:.4f}')\n",
        "            train_loss = 0\n",
        "            bscore = 0\n",
        "            step_time = 0\n",
        "            model.train()\n",
        "        \n",
        "        if global_steps == STEPS:\n",
        "            break\n",
        "    if global_steps == STEPS:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global step: 2000 | Avg_step_time: 0.28s | Train Loss: 3.9194 | Val. Loss: 5.3395 | Train Bleu: 0.1155 | Val. Bleu: 0.0692\n",
            "Global step: 4000 | Avg_step_time: 0.28s | Train Loss: 3.8808 | Val. Loss: 5.3391 | Train Bleu: 0.1212 | Val. Bleu: 0.0694\n",
            "Global step: 6000 | Avg_step_time: 0.28s | Train Loss: 3.8903 | Val. Loss: 5.3374 | Train Bleu: 0.1222 | Val. Bleu: 0.0687\n",
            "Global step: 8000 | Avg_step_time: 0.28s | Train Loss: 3.8852 | Val. Loss: 5.3318 | Train Bleu: 0.1198 | Val. Bleu: 0.0688\n",
            "Global step: 10000 | Avg_step_time: 0.27s | Train Loss: 3.9907 | Val. Loss: 5.2981 | Train Bleu: 0.1200 | Val. Bleu: 0.0698\n",
            "Global step: 12000 | Avg_step_time: 0.28s | Train Loss: 4.0364 | Val. Loss: 5.2789 | Train Bleu: 0.1161 | Val. Bleu: 0.0687\n",
            "Global step: 14000 | Avg_step_time: 0.28s | Train Loss: 3.8710 | Val. Loss: 5.2878 | Train Bleu: 0.1236 | Val. Bleu: 0.0692\n",
            "Global step: 16000 | Avg_step_time: 0.28s | Train Loss: 3.8140 | Val. Loss: 5.2810 | Train Bleu: 0.1281 | Val. Bleu: 0.0688\n",
            "Global step: 18000 | Avg_step_time: 0.29s | Train Loss: 3.8394 | Val. Loss: 5.2747 | Train Bleu: 0.1233 | Val. Bleu: 0.0700\n",
            "Global step: 20000 | Avg_step_time: 0.28s | Train Loss: 3.8381 | Val. Loss: 5.2757 | Train Bleu: 0.1238 | Val. Bleu: 0.0682\n",
            "Global step: 22000 | Avg_step_time: 0.28s | Train Loss: 3.8299 | Val. Loss: 5.2721 | Train Bleu: 0.1273 | Val. Bleu: 0.0695\n",
            "Global step: 24000 | Avg_step_time: 0.28s | Train Loss: 3.9572 | Val. Loss: 5.2678 | Train Bleu: 0.1200 | Val. Bleu: 0.0681\n",
            "Global step: 26000 | Avg_step_time: 0.28s | Train Loss: 3.9838 | Val. Loss: 5.2476 | Train Bleu: 0.1192 | Val. Bleu: 0.0684\n",
            "Global step: 28000 | Avg_step_time: 0.28s | Train Loss: 4.0655 | Val. Loss: 5.2373 | Train Bleu: 0.1183 | Val. Bleu: 0.0694\n",
            "Global step: 30000 | Avg_step_time: 0.28s | Train Loss: 4.0504 | Val. Loss: 5.2422 | Train Bleu: 0.1183 | Val. Bleu: 0.0699\n",
            "Global step: 32000 | Avg_step_time: 0.29s | Train Loss: 4.0274 | Val. Loss: 5.2453 | Train Bleu: 0.1207 | Val. Bleu: 0.0691\n",
            "Global step: 34000 | Avg_step_time: 0.28s | Train Loss: 4.0466 | Val. Loss: 5.2354 | Train Bleu: 0.1168 | Val. Bleu: 0.0697\n",
            "Global step: 36000 | Avg_step_time: 0.28s | Train Loss: 4.0324 | Val. Loss: 5.2432 | Train Bleu: 0.1193 | Val. Bleu: 0.0692\n",
            "Global step: 38000 | Avg_step_time: 0.29s | Train Loss: 4.0241 | Val. Loss: 5.2337 | Train Bleu: 0.1181 | Val. Bleu: 0.0696\n",
            "Global step: 40000 | Avg_step_time: 0.28s | Train Loss: 4.0092 | Val. Loss: 5.2411 | Train Bleu: 0.1213 | Val. Bleu: 0.0699\n",
            "Global step: 42000 | Avg_step_time: 0.28s | Train Loss: 4.0125 | Val. Loss: 5.2304 | Train Bleu: 0.1186 | Val. Bleu: 0.0690\n",
            "Global step: 44000 | Avg_step_time: 0.28s | Train Loss: 4.0192 | Val. Loss: 5.2181 | Train Bleu: 0.1171 | Val. Bleu: 0.0702\n",
            "Global step: 46000 | Avg_step_time: 0.27s | Train Loss: 4.0026 | Val. Loss: 5.2218 | Train Bleu: 0.1184 | Val. Bleu: 0.0698\n",
            "Global step: 48000 | Avg_step_time: 0.28s | Train Loss: 4.0251 | Val. Loss: 5.2108 | Train Bleu: 0.1183 | Val. Bleu: 0.0706\n",
            "Global step: 50000 | Avg_step_time: 0.28s | Train Loss: 4.0070 | Val. Loss: 5.2108 | Train Bleu: 0.1212 | Val. Bleu: 0.0698\n",
            "Global step: 52000 | Avg_step_time: 0.28s | Train Loss: 3.9756 | Val. Loss: 5.2099 | Train Bleu: 0.1225 | Val. Bleu: 0.0696\n",
            "Global step: 54000 | Avg_step_time: 0.28s | Train Loss: 4.0155 | Val. Loss: 5.2199 | Train Bleu: 0.1197 | Val. Bleu: 0.0700\n",
            "Global step: 56000 | Avg_step_time: 0.28s | Train Loss: 3.9853 | Val. Loss: 5.2032 | Train Bleu: 0.1194 | Val. Bleu: 0.0707\n",
            "Global step: 58000 | Avg_step_time: 0.28s | Train Loss: 3.9775 | Val. Loss: 5.2087 | Train Bleu: 0.1219 | Val. Bleu: 0.0701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na-WELLQd0Rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global step: 1000 | Avg_step_time: 0.45s | Train Loss: 7.2874 | Val. Loss: 7.2485 | Train Bleu: 0.0136 | Val. Bleu: 0.0000\n",
        "# Global step: 2000 | Avg_step_time: 0.45s | Train Loss: 6.8569 | Val. Loss: 7.0490 | Train Bleu: 0.0185 | Val. Bleu: 0.0000\n",
        "# Global step: 3000 | Avg_step_time: 0.44s | Train Loss: 6.6827 | Val. Loss: 6.9799 | Train Bleu: 0.0202 | Val. Bleu: 0.0027\n",
        "# Global step: 4000 | Avg_step_time: 0.43s | Train Loss: 6.6085 | Val. Loss: 6.8838 | Train Bleu: 0.0190 | Val. Bleu: 0.0017\n",
        "# Global step: 5000 | Avg_step_time: 0.43s | Train Loss: 6.4932 | Val. Loss: 6.7985 | Train Bleu: 0.0221 | Val. Bleu: 0.0094\n",
        "# Global step: 6000 | Avg_step_time: 0.45s | Train Loss: 6.4123 | Val. Loss: 6.7590 | Train Bleu: 0.0241 | Val. Bleu: 0.0070\n",
        "# Global step: 7000 | Avg_step_time: 0.45s | Train Loss: 6.3443 | Val. Loss: 6.7281 | Train Bleu: 0.0237 | Val. Bleu: 0.0081\n",
        "# Global step: 8000 | Avg_step_time: 0.45s | Train Loss: 6.2755 | Val. Loss: 6.6502 | Train Bleu: 0.0239 | Val. Bleu: 0.0091\n",
        "# Global step: 9000 | Avg_step_time: 0.43s | Train Loss: 6.2054 | Val. Loss: 6.6247 | Train Bleu: 0.0269 | Val. Bleu: 0.0101\n",
        "# Global step: 10000 | Avg_step_time: 0.44s | Train Loss: 6.1481 | Val. Loss: 6.5855 | Train Bleu: 0.0258 | Val. Bleu: 0.0064\n",
        "# Global step: 11000 | Avg_step_time: 0.44s | Train Loss: 6.1050 | Val. Loss: 6.5562 | Train Bleu: 0.0263 | Val. Bleu: 0.0071\n",
        "# Global step: 12000 | Avg_step_time: 0.44s | Train Loss: 6.0624 | Val. Loss: 6.5343 | Train Bleu: 0.0244 | Val. Bleu: 0.0087\n",
        "# Global step: 13000 | Avg_step_time: 0.44s | Train Loss: 5.9604 | Val. Loss: 6.4796 | Train Bleu: 0.0317 | Val. Bleu: 0.0326\n",
        "# Global step: 14000 | Avg_step_time: 0.44s | Train Loss: 5.8751 | Val. Loss: 6.4408 | Train Bleu: 0.0368 | Val. Bleu: 0.0393\n",
        "# Global step: 15000 | Avg_step_time: 0.47s | Train Loss: 5.8402 | Val. Loss: 6.4061 | Train Bleu: 0.0375 | Val. Bleu: 0.0372\n",
        "# Global step: 16000 | Avg_step_time: 0.44s | Train Loss: 5.8188 | Val. Loss: 6.3704 | Train Bleu: 0.0406 | Val. Bleu: 0.0395\n",
        "# Global step: 17000 | Avg_step_time: 0.45s | Train Loss: 5.7751 | Val. Loss: 6.3449 | Train Bleu: 0.0399 | Val. Bleu: 0.0409\n",
        "# Global step: 18000 | Avg_step_time: 0.45s | Train Loss: 5.6975 | Val. Loss: 6.3040 | Train Bleu: 0.0412 | Val. Bleu: 0.0422\n",
        "# Global step: 19000 | Avg_step_time: 0.44s | Train Loss: 5.6821 | Val. Loss: 6.3286 | Train Bleu: 0.0435 | Val. Bleu: 0.0423\n",
        "# Global step: 20000 | Avg_step_time: 0.44s | Train Loss: 5.6444 | Val. Loss: 6.2735 | Train Bleu: 0.0445 | Val. Bleu: 0.0414\n",
        "# Global step: 21000 | Avg_step_time: 0.45s | Train Loss: 5.6347 | Val. Loss: 6.2511 | Train Bleu: 0.0451 | Val. Bleu: 0.0426\n",
        "# Global step: 22000 | Avg_step_time: 0.44s | Train Loss: 5.5880 | Val. Loss: 6.2053 | Train Bleu: 0.0461 | Val. Bleu: 0.0432\n",
        "# Global step: 23000 | Avg_step_time: 0.44s | Train Loss: 5.5875 | Val. Loss: 6.2302 | Train Bleu: 0.0450 | Val. Bleu: 0.0427\n",
        "# Global step: 24000 | Avg_step_time: 0.44s | Train Loss: 5.5366 | Val. Loss: 6.2192 | Train Bleu: 0.0471 | Val. Bleu: 0.0449\n",
        "# Global step: 25000 | Avg_step_time: 0.45s | Train Loss: 5.5287 | Val. Loss: 6.2073 | Train Bleu: 0.0474 | Val. Bleu: 0.0443\n",
        "# Global step: 26000 | Avg_step_time: 0.45s | Train Loss: 5.5349 | Val. Loss: 6.1741 | Train Bleu: 0.0507 | Val. Bleu: 0.0444\n",
        "# Global step: 27000 | Avg_step_time: 0.44s | Train Loss: 5.4930 | Val. Loss: 6.1724 | Train Bleu: 0.0503 | Val. Bleu: 0.0447\n",
        "# Global step: 28000 | Avg_step_time: 0.48s | Train Loss: 5.4818 | Val. Loss: 6.1400 | Train Bleu: 0.0516 | Val. Bleu: 0.0442\n",
        "# Global step: 29000 | Avg_step_time: 0.45s | Train Loss: 5.4495 | Val. Loss: 6.1142 | Train Bleu: 0.0513 | Val. Bleu: 0.0454\n",
        "# Global step: 30000 | Avg_step_time: 0.45s | Train Loss: 5.4226 | Val. Loss: 6.1115 | Train Bleu: 0.0523 | Val. Bleu: 0.0450\n",
        "# Global step: 31000 | Avg_step_time: 0.44s | Train Loss: 5.4017 | Val. Loss: 6.1262 | Train Bleu: 0.0529 | Val. Bleu: 0.0455\n",
        "# Global step: 32000 | Avg_step_time: 0.45s | Train Loss: 5.4129 | Val. Loss: 6.0849 | Train Bleu: 0.0522 | Val. Bleu: 0.0470\n",
        "# Global step: 33000 | Avg_step_time: 0.45s | Train Loss: 5.3834 | Val. Loss: 6.0847 | Train Bleu: 0.0546 | Val. Bleu: 0.0451\n",
        "# Global step: 34000 | Avg_step_time: 0.46s | Train Loss: 5.3263 | Val. Loss: 6.0765 | Train Bleu: 0.0569 | Val. Bleu: 0.0465\n",
        "# Global step: 35000 | Avg_step_time: 0.46s | Train Loss: 5.3109 | Val. Loss: 6.0739 | Train Bleu: 0.0549 | Val. Bleu: 0.0477\n",
        "# Global step: 36000 | Avg_step_time: 0.47s | Train Loss: 5.2960 | Val. Loss: 6.0581 | Train Bleu: 0.0554 | Val. Bleu: 0.0472\n",
        "# Global step: 37000 | Avg_step_time: 0.47s | Train Loss: 5.2860 | Val. Loss: 6.0518 | Train Bleu: 0.0568 | Val. Bleu: 0.0483\n",
        "# Global step: 38000 | Avg_step_time: 0.44s | Train Loss: 5.2539 | Val. Loss: 6.0308 | Train Bleu: 0.0567 | Val. Bleu: 0.0460\n",
        "# Global step: 39000 | Avg_step_time: 0.45s | Train Loss: 5.2928 | Val. Loss: 6.0032 | Train Bleu: 0.0595 | Val. Bleu: 0.0466\n",
        "# Global step: 40000 | Avg_step_time: 0.46s | Train Loss: 5.2489 | Val. Loss: 6.0163 | Train Bleu: 0.0569 | Val. Bleu: 0.0478\n",
        "# Global step: 41000 | Avg_step_time: 0.45s | Train Loss: 5.2265 | Val. Loss: 5.9990 | Train Bleu: 0.0595 | Val. Bleu: 0.0475\n",
        "# Global step: 42000 | Avg_step_time: 0.45s | Train Loss: 5.2154 | Val. Loss: 5.9700 | Train Bleu: 0.0595 | Val. Bleu: 0.0493\n",
        "# Global step: 43000 | Avg_step_time: 0.44s | Train Loss: 5.1963 | Val. Loss: 5.9610 | Train Bleu: 0.0605 | Val. Bleu: 0.0482\n",
        "# Global step: 44000 | Avg_step_time: 0.44s | Train Loss: 5.1567 | Val. Loss: 5.9695 | Train Bleu: 0.0595 | Val. Bleu: 0.0483\n",
        "# Global step: 45000 | Avg_step_time: 0.46s | Train Loss: 5.1188 | Val. Loss: 5.9379 | Train Bleu: 0.0616 | Val. Bleu: 0.0489\n",
        "# Global step: 46000 | Avg_step_time: 0.45s | Train Loss: 5.1374 | Val. Loss: 5.9547 | Train Bleu: 0.0616 | Val. Bleu: 0.0489\n",
        "# Global step: 47000 | Avg_step_time: 0.47s | Train Loss: 5.1879 | Val. Loss: 5.9247 | Train Bleu: 0.0608 | Val. Bleu: 0.0486\n",
        "# Global step: 48000 | Avg_step_time: 0.44s | Train Loss: 5.0934 | Val. Loss: 5.9262 | Train Bleu: 0.0639 | Val. Bleu: 0.0479\n",
        "# Global step: 49000 | Avg_step_time: 0.46s | Train Loss: 5.0855 | Val. Loss: 5.8980 | Train Bleu: 0.0650 | Val. Bleu: 0.0497\n",
        "# Global step: 50000 | Avg_step_time: 0.45s | Train Loss: 5.0911 | Val. Loss: 5.8933 | Train Bleu: 0.0636 | Val. Bleu: 0.0485\n",
        "# Global step: 51000 | Avg_step_time: 0.45s | Train Loss: 5.0742 | Val. Loss: 5.8865 | Train Bleu: 0.0631 | Val. Bleu: 0.0495\n",
        "# Global step: 52000 | Avg_step_time: 0.45s | Train Loss: 5.0412 | Val. Loss: 5.8828 | Train Bleu: 0.0646 | Val. Bleu: 0.0499\n",
        "# Global step: 53000 | Avg_step_time: 0.45s | Train Loss: 5.0398 | Val. Loss: 5.8482 | Train Bleu: 0.0642 | Val. Bleu: 0.0496\n",
        "# Global step: 54000 | Avg_step_time: 0.45s | Train Loss: 5.0180 | Val. Loss: 5.8708 | Train Bleu: 0.0646 | Val. Bleu: 0.0485\n",
        "\n",
        "# Global step: 2000 | Avg_step_time: 0.30s | Train Loss: 5.3315 | Val. Loss: 6.2003 | Train Bleu: 0.0558 | Val. Bleu: 0.0462\n",
        "# Global step: 4000 | Avg_step_time: 0.29s | Train Loss: 5.3448 | Val. Loss: 6.1103 | Train Bleu: 0.0574 | Val. Bleu: 0.0484\n",
        "# Global step: 6000 | Avg_step_time: 0.29s | Train Loss: 5.3109 | Val. Loss: 6.0868 | Train Bleu: 0.0589 | Val. Bleu: 0.0477\n",
        "# Global step: 8000 | Avg_step_time: 0.29s | Train Loss: 5.2975 | Val. Loss: 6.0407 | Train Bleu: 0.0589 | Val. Bleu: 0.0495\n",
        "# Global step: 10000 | Avg_step_time: 0.29s | Train Loss: 5.2201 | Val. Loss: 6.0197 | Train Bleu: 0.0615 | Val. Bleu: 0.0497\n",
        "# Global step: 12000 | Avg_step_time: 0.29s | Train Loss: 5.2164 | Val. Loss: 5.9907 | Train Bleu: 0.0614 | Val. Bleu: 0.0493\n",
        "# Global step: 14000 | Avg_step_time: 0.29s | Train Loss: 5.1898 | Val. Loss: 5.9506 | Train Bleu: 0.0626 | Val. Bleu: 0.0503\n",
        "# Global step: 16000 | Avg_step_time: 0.30s | Train Loss: 5.1479 | Val. Loss: 5.9502 | Train Bleu: 0.0641 | Val. Bleu: 0.0528\n",
        "# Global step: 18000 | Avg_step_time: 0.29s | Train Loss: 5.1007 | Val. Loss: 5.9500 | Train Bleu: 0.0645 | Val. Bleu: 0.0525\n",
        "# Global step: 20000 | Avg_step_time: 0.29s | Train Loss: 5.0753 | Val. Loss: 5.9107 | Train Bleu: 0.0671 | Val. Bleu: 0.0517\n",
        "# Global step: 22000 | Avg_step_time: 0.29s | Train Loss: 5.0850 | Val. Loss: 5.8950 | Train Bleu: 0.0676 | Val. Bleu: 0.0518\n",
        "# Global step: 24000 | Avg_step_time: 0.29s | Train Loss: 5.0563 | Val. Loss: 5.8839 | Train Bleu: 0.0662 | Val. Bleu: 0.0529\n",
        "# Global step: 26000 | Avg_step_time: 0.29s | Train Loss: 5.0401 | Val. Loss: 5.9325 | Train Bleu: 0.0678 | Val. Bleu: 0.0515\n",
        "# Global step: 28000 | Avg_step_time: 0.29s | Train Loss: 4.9876 | Val. Loss: 5.8915 | Train Bleu: 0.0701 | Val. Bleu: 0.0536\n",
        "# Global step: 30000 | Avg_step_time: 0.31s | Train Loss: 4.9898 | Val. Loss: 5.8922 | Train Bleu: 0.0706 | Val. Bleu: 0.0551\n",
        "# Global step: 32000 | Avg_step_time: 0.30s | Train Loss: 4.9994 | Val. Loss: 5.9162 | Train Bleu: 0.0720 | Val. Bleu: 0.0537\n",
        "# Global step: 34000 | Avg_step_time: 0.30s | Train Loss: 4.9680 | Val. Loss: 5.9021 | Train Bleu: 0.0722 | Val. Bleu: 0.0539\n",
        "# Global step: 36000 | Avg_step_time: 0.30s | Train Loss: 4.9362 | Val. Loss: 5.8346 | Train Bleu: 0.0713 | Val. Bleu: 0.0549\n",
        "# Global step: 38000 | Avg_step_time: 0.29s | Train Loss: 4.9276 | Val. Loss: 5.8316 | Train Bleu: 0.0758 | Val. Bleu: 0.0550\n",
        "# Global step: 40000 | Avg_step_time: 0.29s | Train Loss: 4.9058 | Val. Loss: 5.8548 | Train Bleu: 0.0763 | Val. Bleu: 0.0538\n",
        "# Global step: 42000 | Avg_step_time: 0.29s | Train Loss: 4.9413 | Val. Loss: 5.8239 | Train Bleu: 0.0735 | Val. Bleu: 0.0544\n",
        "# Global step: 44000 | Avg_step_time: 0.29s | Train Loss: 4.8981 | Val. Loss: 5.8157 | Train Bleu: 0.0768 | Val. Bleu: 0.0548\n",
        "# Global step: 46000 | Avg_step_time: 0.29s | Train Loss: 4.9041 | Val. Loss: 5.8420 | Train Bleu: 0.0763 | Val. Bleu: 0.0546\n",
        "# Global step: 48000 | Avg_step_time: 0.29s | Train Loss: 4.8608 | Val. Loss: 5.7974 | Train Bleu: 0.0776 | Val. Bleu: 0.0557\n",
        "# Global step: 50000 | Avg_step_time: 0.30s | Train Loss: 4.8674 | Val. Loss: 5.8028 | Train Bleu: 0.0779 | Val. Bleu: 0.0559\n",
        "# Global step: 52000 | Avg_step_time: 0.30s | Train Loss: 4.8790 | Val. Loss: 5.8420 | Train Bleu: 0.0783 | Val. Bleu: 0.0553\n",
        "# Global step: 54000 | Avg_step_time: 0.29s | Train Loss: 4.8392 | Val. Loss: 5.8121 | Train Bleu: 0.0783 | Val. Bleu: 0.0568\n",
        "# Global step: 56000 | Avg_step_time: 0.31s | Train Loss: 4.8577 | Val. Loss: 5.7938 | Train Bleu: 0.0802 | Val. Bleu: 0.0565\n",
        "# Global step: 58000 | Avg_step_time: 0.29s | Train Loss: 4.8316 | Val. Loss: 5.8004 | Train Bleu: 0.0793 | Val. Bleu: 0.0563\n",
        "# Global step: 60000 | Avg_step_time: 0.29s | Train Loss: 4.8270 | Val. Loss: 5.7785 | Train Bleu: 0.0804 | Val. Bleu: 0.0557\n",
        "# Global step: 62000 | Avg_step_time: 0.29s | Train Loss: 4.8003 | Val. Loss: 5.7962 | Train Bleu: 0.0806 | Val. Bleu: 0.0567\n",
        "# Global step: 64000 | Avg_step_time: 0.30s | Train Loss: 4.8393 | Val. Loss: 5.7628 | Train Bleu: 0.0805 | Val. Bleu: 0.0568\n",
        "# Global step: 66000 | Avg_step_time: 0.29s | Train Loss: 4.7920 | Val. Loss: 5.7719 | Train Bleu: 0.0821 | Val. Bleu: 0.0560\n",
        "# Global step: 68000 | Avg_step_time: 0.30s | Train Loss: 4.7609 | Val. Loss: 5.7561 | Train Bleu: 0.0829 | Val. Bleu: 0.0578\n",
        "# Global step: 70000 | Avg_step_time: 0.30s | Train Loss: 4.7515 | Val. Loss: 5.7504 | Train Bleu: 0.0847 | Val. Bleu: 0.0585\n",
        "# Global step: 72000 | Avg_step_time: 0.31s | Train Loss: 4.7548 | Val. Loss: 5.7666 | Train Bleu: 0.0818 | Val. Bleu: 0.0581\n",
        "# Global step: 74000 | Avg_step_time: 0.30s | Train Loss: 4.7479 | Val. Loss: 5.7937 | Train Bleu: 0.0838 | Val. Bleu: 0.0556\n",
        "# Global step: 76000 | Avg_step_time: 0.29s | Train Loss: 4.7218 | Val. Loss: 5.7392 | Train Bleu: 0.0833 | Val. Bleu: 0.0589\n",
        "# Global step: 78000 | Avg_step_time: 0.29s | Train Loss: 4.7956 | Val. Loss: 5.7209 | Train Bleu: 0.0839 | Val. Bleu: 0.0584\n",
        "# Global step: 80000 | Avg_step_time: 0.30s | Train Loss: 4.7553 | Val. Loss: 5.7246 | Train Bleu: 0.0822 | Val. Bleu: 0.0574\n",
        "# Global step: 82000 | Avg_step_time: 0.29s | Train Loss: 4.7506 | Val. Loss: 5.7096 | Train Bleu: 0.0849 | Val. Bleu: 0.0579\n",
        "# Global step: 84000 | Avg_step_time: 0.29s | Train Loss: 4.7412 | Val. Loss: 5.7048 | Train Bleu: 0.0840 | Val. Bleu: 0.0589\n",
        "# Global step: 86000 | Avg_step_time: 0.29s | Train Loss: 4.7324 | Val. Loss: 5.7003 | Train Bleu: 0.0856 | Val. Bleu: 0.0582\n",
        "# Global step: 88000 | Avg_step_time: 0.29s | Train Loss: 4.7125 | Val. Loss: 5.6950 | Train Bleu: 0.0866 | Val. Bleu: 0.0577\n",
        "# Global step: 90000 | Avg_step_time: 0.30s | Train Loss: 4.6858 | Val. Loss: 5.7063 | Train Bleu: 0.0864 | Val. Bleu: 0.0578\n",
        "# Global step: 92000 | Avg_step_time: 0.30s | Train Loss: 4.7028 | Val. Loss: 5.7069 | Train Bleu: 0.0856 | Val. Bleu: 0.0582\n",
        "# Global step: 94000 | Avg_step_time: 0.30s | Train Loss: 4.7323 | Val. Loss: 5.6757 | Train Bleu: 0.0851 | Val. Bleu: 0.0592\n",
        "# Global step: 96000 | Avg_step_time: 0.29s | Train Loss: 4.6713 | Val. Loss: 5.6982 | Train Bleu: 0.0873 | Val. Bleu: 0.0579\n",
        "# Global step: 98000 | Avg_step_time: 0.30s | Train Loss: 4.6876 | Val. Loss: 5.6984 | Train Bleu: 0.0892 | Val. Bleu: 0.0604\n",
        "# Global step: 100000 | Avg_step_time: 0.30s | Train Loss: 4.7205 | Val. Loss: 5.6711 | Train Bleu: 0.0891 | Val. Bleu: 0.0569\n",
        "# Global step: 102000 | Avg_step_time: 0.29s | Train Loss: 4.7184 | Val. Loss: 5.6771 | Train Bleu: 0.0847 | Val. Bleu: 0.0591\n",
        "# Global step: 104000 | Avg_step_time: 0.30s | Train Loss: 4.6883 | Val. Loss: 5.6759 | Train Bleu: 0.0869 | Val. Bleu: 0.0603\n",
        "# Global step: 106000 | Avg_step_time: 0.30s | Train Loss: 4.7064 | Val. Loss: 5.6517 | Train Bleu: 0.0878 | Val. Bleu: 0.0609\n",
        "# Global step: 108000 | Avg_step_time: 0.29s | Train Loss: 4.6729 | Val. Loss: 5.6762 | Train Bleu: 0.0889 | Val. Bleu: 0.0615\n",
        "# Global step: 110000 | Avg_step_time: 0.31s | Train Loss: 4.6739 | Val. Loss: 5.6413 | Train Bleu: 0.0903 | Val. Bleu: 0.0605\n",
        "# Global step: 112000 | Avg_step_time: 0.30s | Train Loss: 4.6816 | Val. Loss: 5.6564 | Train Bleu: 0.0907 | Val. Bleu: 0.0589\n",
        "# Global step: 114000 | Avg_step_time: 0.30s | Train Loss: 4.6387 | Val. Loss: 5.6276 | Train Bleu: 0.0914 | Val. Bleu: 0.0598\n",
        "# Global step: 116000 | Avg_step_time: 0.29s | Train Loss: 4.6749 | Val. Loss: 5.6465 | Train Bleu: 0.0907 | Val. Bleu: 0.0583\n",
        "\n",
        "# Global step: 2000 | Avg_step_time: 0.18s | Train Loss: 4.7019 | Val. Loss: 5.8130 | Train Bleu: 0.0897 | Val. Bleu: 0.0612\n",
        "# Global step: 4000 | Avg_step_time: 0.18s | Train Loss: 4.7334 | Val. Loss: 5.7931 | Train Bleu: 0.0894 | Val. Bleu: 0.0613\n",
        "# Global step: 6000 | Avg_step_time: 0.18s | Train Loss: 4.7022 | Val. Loss: 5.7723 | Train Bleu: 0.0900 | Val. Bleu: 0.0607\n",
        "# Global step: 8000 | Avg_step_time: 0.17s | Train Loss: 4.6688 | Val. Loss: 5.7482 | Train Bleu: 0.0927 | Val. Bleu: 0.0608\n",
        "# Global step: 10000 | Avg_step_time: 0.18s | Train Loss: 4.6702 | Val. Loss: 5.7098 | Train Bleu: 0.0906 | Val. Bleu: 0.0611\n",
        "# Global step: 12000 | Avg_step_time: 0.18s | Train Loss: 4.6160 | Val. Loss: 5.6928 | Train Bleu: 0.0913 | Val. Bleu: 0.0621\n",
        "# Global step: 14000 | Avg_step_time: 0.17s | Train Loss: 4.6287 | Val. Loss: 5.6837 | Train Bleu: 0.0893 | Val. Bleu: 0.0596\n",
        "# Global step: 16000 | Avg_step_time: 0.17s | Train Loss: 4.5639 | Val. Loss: 5.6355 | Train Bleu: 0.0950 | Val. Bleu: 0.0606\n",
        "# Global step: 18000 | Avg_step_time: 0.18s | Train Loss: 4.5463 | Val. Loss: 5.6251 | Train Bleu: 0.0939 | Val. Bleu: 0.0606\n",
        "# Global step: 20000 | Avg_step_time: 0.18s | Train Loss: 4.5623 | Val. Loss: 5.6140 | Train Bleu: 0.0962 | Val. Bleu: 0.0608\n",
        "# Global step: 22000 | Avg_step_time: 0.18s | Train Loss: 4.5380 | Val. Loss: 5.6025 | Train Bleu: 0.0934 | Val. Bleu: 0.0606\n",
        "# Global step: 24000 | Avg_step_time: 0.18s | Train Loss: 4.5779 | Val. Loss: 5.6119 | Train Bleu: 0.0950 | Val. Bleu: 0.0609\n",
        "# Global step: 26000 | Avg_step_time: 0.18s | Train Loss: 4.4960 | Val. Loss: 5.6009 | Train Bleu: 0.0936 | Val. Bleu: 0.0621\n",
        "# Global step: 28000 | Avg_step_time: 0.18s | Train Loss: 4.5105 | Val. Loss: 5.5870 | Train Bleu: 0.0972 | Val. Bleu: 0.0628\n",
        "# Global step: 30000 | Avg_step_time: 0.18s | Train Loss: 4.5316 | Val. Loss: 5.5717 | Train Bleu: 0.0946 | Val. Bleu: 0.0610\n",
        "# Global step: 32000 | Avg_step_time: 0.17s | Train Loss: 4.4818 | Val. Loss: 5.5671 | Train Bleu: 0.0940 | Val. Bleu: 0.0618\n",
        "# Global step: 34000 | Avg_step_time: 0.18s | Train Loss: 4.5132 | Val. Loss: 5.5703 | Train Bleu: 0.0958 | Val. Bleu: 0.0632\n",
        "# Global step: 36000 | Avg_step_time: 0.18s | Train Loss: 4.4833 | Val. Loss: 5.5677 | Train Bleu: 0.0969 | Val. Bleu: 0.0636\n",
        "# Global step: 38000 | Avg_step_time: 0.18s | Train Loss: 4.4812 | Val. Loss: 5.5862 | Train Bleu: 0.0966 | Val. Bleu: 0.0621\n",
        "# Global step: 40000 | Avg_step_time: 0.18s | Train Loss: 4.4966 | Val. Loss: 5.6195 | Train Bleu: 0.0967 | Val. Bleu: 0.0626\n",
        "# Global step: 42000 | Avg_step_time: 0.18s | Train Loss: 4.4808 | Val. Loss: 5.5646 | Train Bleu: 0.0971 | Val. Bleu: 0.0624\n",
        "# Global step: 44000 | Avg_step_time: 0.18s | Train Loss: 4.4756 | Val. Loss: 5.5635 | Train Bleu: 0.0978 | Val. Bleu: 0.0632\n",
        "# Global step: 46000 | Avg_step_time: 0.18s | Train Loss: 4.4644 | Val. Loss: 5.5422 | Train Bleu: 0.0973 | Val. Bleu: 0.0628\n",
        "# Global step: 48000 | Avg_step_time: 0.17s | Train Loss: 4.4838 | Val. Loss: 5.5662 | Train Bleu: 0.1004 | Val. Bleu: 0.0629\n",
        "# Global step: 50000 | Avg_step_time: 0.18s | Train Loss: 4.4797 | Val. Loss: 5.5397 | Train Bleu: 0.0987 | Val. Bleu: 0.0635\n",
        "# Global step: 52000 | Avg_step_time: 0.18s | Train Loss: 4.4823 | Val. Loss: 5.5637 | Train Bleu: 0.0979 | Val. Bleu: 0.0626\n",
        "# Global step: 54000 | Avg_step_time: 0.18s | Train Loss: 4.4756 | Val. Loss: 5.5191 | Train Bleu: 0.0978 | Val. Bleu: 0.0627\n",
        "# Global step: 56000 | Avg_step_time: 0.17s | Train Loss: 4.4530 | Val. Loss: 5.5405 | Train Bleu: 0.0994 | Val. Bleu: 0.0638\n",
        "# Global step: 58000 | Avg_step_time: 0.18s | Train Loss: 4.4519 | Val. Loss: 5.5148 | Train Bleu: 0.0997 | Val. Bleu: 0.0633\n",
        "# Global step: 60000 | Avg_step_time: 0.18s | Train Loss: 4.4327 | Val. Loss: 5.5157 | Train Bleu: 0.0994 | Val. Bleu: 0.0625\n",
        "# Global step: 62000 | Avg_step_time: 0.18s | Train Loss: 4.4546 | Val. Loss: 5.5269 | Train Bleu: 0.0982 | Val. Bleu: 0.0642\n",
        "# Global step: 64000 | Avg_step_time: 0.18s | Train Loss: 4.4754 | Val. Loss: 5.4940 | Train Bleu: 0.0979 | Val. Bleu: 0.0632\n",
        "# Global step: 66000 | Avg_step_time: 0.18s | Train Loss: 4.4336 | Val. Loss: 5.4972 | Train Bleu: 0.0979 | Val. Bleu: 0.0653\n",
        "# Global step: 68000 | Avg_step_time: 0.18s | Train Loss: 4.4126 | Val. Loss: 5.5228 | Train Bleu: 0.0999 | Val. Bleu: 0.0654\n",
        "# Global step: 70000 | Avg_step_time: 0.18s | Train Loss: 4.4254 | Val. Loss: 5.5273 | Train Bleu: 0.0991 | Val. Bleu: 0.0645\n",
        "# Global step: 72000 | Avg_step_time: 0.18s | Train Loss: 4.4439 | Val. Loss: 5.5034 | Train Bleu: 0.1011 | Val. Bleu: 0.0638\n",
        "# Global step: 74000 | Avg_step_time: 0.19s | Train Loss: 4.4052 | Val. Loss: 5.4969 | Train Bleu: 0.1004 | Val. Bleu: 0.0644\n",
        "# Global step: 76000 | Avg_step_time: 0.18s | Train Loss: 4.4013 | Val. Loss: 5.5243 | Train Bleu: 0.1008 | Val. Bleu: 0.0632\n",
        "# Global step: 78000 | Avg_step_time: 0.18s | Train Loss: 4.4312 | Val. Loss: 5.5218 | Train Bleu: 0.0982 | Val. Bleu: 0.0630\n",
        "# Global step: 80000 | Avg_step_time: 0.18s | Train Loss: 4.4224 | Val. Loss: 5.5492 | Train Bleu: 0.1021 | Val. Bleu: 0.0635\n",
        "# Global step: 82000 | Avg_step_time: 0.19s | Train Loss: 4.4201 | Val. Loss: 5.5193 | Train Bleu: 0.0991 | Val. Bleu: 0.0630\n",
        "# Global step: 84000 | Avg_step_time: 0.19s | Train Loss: 4.3809 | Val. Loss: 5.5282 | Train Bleu: 0.1016 | Val. Bleu: 0.0655\n",
        "# Global step: 86000 | Avg_step_time: 0.18s | Train Loss: 4.4216 | Val. Loss: 5.5245 | Train Bleu: 0.0994 | Val. Bleu: 0.0655\n",
        "# Global step: 88000 | Avg_step_time: 0.18s | Train Loss: 4.4089 | Val. Loss: 5.5336 | Train Bleu: 0.1030 | Val. Bleu: 0.0640\n",
        "\n",
        "# Global step: 2000 | Avg_step_time: 0.46s | Train Loss: 4.2803 | Val. Loss: 5.4556 | Train Bleu: 0.1040 | Val. Bleu: 0.0660\n",
        "# Global step: 4000 | Avg_step_time: 0.44s | Train Loss: 4.2345 | Val. Loss: 5.4405 | Train Bleu: 0.1049 | Val. Bleu: 0.0652\n",
        "# Global step: 6000 | Avg_step_time: 0.46s | Train Loss: 4.2340 | Val. Loss: 5.4303 | Train Bleu: 0.1035 | Val. Bleu: 0.0660\n",
        "# Global step: 8000 | Avg_step_time: 0.45s | Train Loss: 4.1643 | Val. Loss: 5.3716 | Train Bleu: 0.1073 | Val. Bleu: 0.0653\n",
        "# Global step: 10000 | Avg_step_time: 0.45s | Train Loss: 4.1589 | Val. Loss: 5.3680 | Train Bleu: 0.1085 | Val. Bleu: 0.0672\n",
        "# Global step: 12000 | Avg_step_time: 0.44s | Train Loss: 4.1662 | Val. Loss: 5.3446 | Train Bleu: 0.1065 | Val. Bleu: 0.0675\n",
        "# Global step: 14000 | Avg_step_time: 0.43s | Train Loss: 4.1633 | Val. Loss: 5.3454 | Train Bleu: 0.1066 | Val. Bleu: 0.0677\n",
        "# Global step: 16000 | Avg_step_time: 0.44s | Train Loss: 4.1312 | Val. Loss: 5.3118 | Train Bleu: 0.1067 | Val. Bleu: 0.0678\n",
        "# Global step: 18000 | Avg_step_time: 0.44s | Train Loss: 4.1144 | Val. Loss: 5.3314 | Train Bleu: 0.1098 | Val. Bleu: 0.0667\n",
        "# Global step: 20000 | Avg_step_time: 0.45s | Train Loss: 4.0986 | Val. Loss: 5.3075 | Train Bleu: 0.1106 | Val. Bleu: 0.0660\n",
        "# Global step: 22000 | Avg_step_time: 0.45s | Train Loss: 4.0948 | Val. Loss: 5.3167 | Train Bleu: 0.1095 | Val. Bleu: 0.0680\n",
        "# Global step: 24000 | Avg_step_time: 0.45s | Train Loss: 4.0968 | Val. Loss: 5.3086 | Train Bleu: 0.1096 | Val. Bleu: 0.0671\n",
        "# Global step: 26000 | Avg_step_time: 0.45s | Train Loss: 4.1153 | Val. Loss: 5.3092 | Train Bleu: 0.1089 | Val. Bleu: 0.0646\n",
        "# Global step: 28000 | Avg_step_time: 0.45s | Train Loss: 4.0759 | Val. Loss: 5.2931 | Train Bleu: 0.1114 | Val. Bleu: 0.0682\n",
        "# Global step: 30000 | Avg_step_time: 0.44s | Train Loss: 4.0966 | Val. Loss: 5.2990 | Train Bleu: 0.1127 | Val. Bleu: 0.0663\n",
        "\n",
        "# Global step: 2000 | Avg_step_time: 0.28s | Train Loss: 3.9194 | Val. Loss: 5.3395 | Train Bleu: 0.1155 | Val. Bleu: 0.0692\n",
        "# Global step: 4000 | Avg_step_time: 0.28s | Train Loss: 3.8808 | Val. Loss: 5.3391 | Train Bleu: 0.1212 | Val. Bleu: 0.0694\n",
        "# Global step: 6000 | Avg_step_time: 0.28s | Train Loss: 3.8903 | Val. Loss: 5.3374 | Train Bleu: 0.1222 | Val. Bleu: 0.0687\n",
        "# Global step: 8000 | Avg_step_time: 0.28s | Train Loss: 3.8852 | Val. Loss: 5.3318 | Train Bleu: 0.1198 | Val. Bleu: 0.0688\n",
        "# Global step: 10000 | Avg_step_time: 0.27s | Train Loss: 3.9907 | Val. Loss: 5.2981 | Train Bleu: 0.1200 | Val. Bleu: 0.0698\n",
        "# Global step: 12000 | Avg_step_time: 0.28s | Train Loss: 4.0364 | Val. Loss: 5.2789 | Train Bleu: 0.1161 | Val. Bleu: 0.0687\n",
        "# Global step: 14000 | Avg_step_time: 0.28s | Train Loss: 3.8710 | Val. Loss: 5.2878 | Train Bleu: 0.1236 | Val. Bleu: 0.0692\n",
        "# Global step: 16000 | Avg_step_time: 0.28s | Train Loss: 3.8140 | Val. Loss: 5.2810 | Train Bleu: 0.1281 | Val. Bleu: 0.0688\n",
        "# Global step: 18000 | Avg_step_time: 0.29s | Train Loss: 3.8394 | Val. Loss: 5.2747 | Train Bleu: 0.1233 | Val. Bleu: 0.0700\n",
        "# Global step: 20000 | Avg_step_time: 0.28s | Train Loss: 3.8381 | Val. Loss: 5.2757 | Train Bleu: 0.1238 | Val. Bleu: 0.0682\n",
        "# Global step: 22000 | Avg_step_time: 0.28s | Train Loss: 3.8299 | Val. Loss: 5.2721 | Train Bleu: 0.1273 | Val. Bleu: 0.0695\n",
        "# Global step: 24000 | Avg_step_time: 0.28s | Train Loss: 3.9572 | Val. Loss: 5.2678 | Train Bleu: 0.1200 | Val. Bleu: 0.0681\n",
        "# Global step: 26000 | Avg_step_time: 0.28s | Train Loss: 3.9838 | Val. Loss: 5.2476 | Train Bleu: 0.1192 | Val. Bleu: 0.0684\n",
        "# Global step: 28000 | Avg_step_time: 0.28s | Train Loss: 4.0655 | Val. Loss: 5.2373 | Train Bleu: 0.1183 | Val. Bleu: 0.0694\n",
        "# Global step: 30000 | Avg_step_time: 0.28s | Train Loss: 4.0504 | Val. Loss: 5.2422 | Train Bleu: 0.1183 | Val. Bleu: 0.0699\n",
        "# Global step: 32000 | Avg_step_time: 0.29s | Train Loss: 4.0274 | Val. Loss: 5.2453 | Train Bleu: 0.1207 | Val. Bleu: 0.0691\n",
        "# Global step: 34000 | Avg_step_time: 0.28s | Train Loss: 4.0466 | Val. Loss: 5.2354 | Train Bleu: 0.1168 | Val. Bleu: 0.0697\n",
        "# Global step: 36000 | Avg_step_time: 0.28s | Train Loss: 4.0324 | Val. Loss: 5.2432 | Train Bleu: 0.1193 | Val. Bleu: 0.0692\n",
        "# Global step: 38000 | Avg_step_time: 0.29s | Train Loss: 4.0241 | Val. Loss: 5.2337 | Train Bleu: 0.1181 | Val. Bleu: 0.0696\n",
        "# Global step: 40000 | Avg_step_time: 0.28s | Train Loss: 4.0092 | Val. Loss: 5.2411 | Train Bleu: 0.1213 | Val. Bleu: 0.0699\n",
        "# Global step: 42000 | Avg_step_time: 0.28s | Train Loss: 4.0125 | Val. Loss: 5.2304 | Train Bleu: 0.1186 | Val. Bleu: 0.0690\n",
        "# Global step: 44000 | Avg_step_time: 0.28s | Train Loss: 4.0192 | Val. Loss: 5.2181 | Train Bleu: 0.1171 | Val. Bleu: 0.0702\n",
        "# Global step: 46000 | Avg_step_time: 0.27s | Train Loss: 4.0026 | Val. Loss: 5.2218 | Train Bleu: 0.1184 | Val. Bleu: 0.0698\n",
        "# Global step: 48000 | Avg_step_time: 0.28s | Train Loss: 4.0251 | Val. Loss: 5.2108 | Train Bleu: 0.1183 | Val. Bleu: 0.0706\n",
        "# Global step: 50000 | Avg_step_time: 0.28s | Train Loss: 4.0070 | Val. Loss: 5.2108 | Train Bleu: 0.1212 | Val. Bleu: 0.0698\n",
        "# Global step: 52000 | Avg_step_time: 0.28s | Train Loss: 3.9756 | Val. Loss: 5.2099 | Train Bleu: 0.1225 | Val. Bleu: 0.0696\n",
        "# Global step: 54000 | Avg_step_time: 0.28s | Train Loss: 4.0155 | Val. Loss: 5.2199 | Train Bleu: 0.1197 | Val. Bleu: 0.0700\n",
        "# Global step: 56000 | Avg_step_time: 0.28s | Train Loss: 3.9853 | Val. Loss: 5.2032 | Train Bleu: 0.1194 | Val. Bleu: 0.0707\n",
        "# Global step: 58000 | Avg_step_time: 0.28s | Train Loss: 3.9775 | Val. Loss: 5.2087 | Train Bleu: 0.1219 | Val. Bleu: 0.0701"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brIB4EGid0r_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM3a3YN5jBos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GiEOM2FjBhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBhPKig0jBf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xYcrnjBXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdOENu2LjBPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2z_ZOhM1Tix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}